{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing dirty data with ticdat\n",
    "\n",
    "Dirty data is an unloved and often overlooked challenge when building analytical models. A typical assumption is that the input data to a model will somehow magically be clean. In reality, there are any number of reasons why dirty data might be passed as input to your engine. The data might be munged together from different systems, the requirements of your data model might be poorly understood, or a user might be simply pushing your model to its limits via what-if analysis. Regardless of the cause, a professional engine will respond gracefully when passed input data that violates basic integrity checks.\n",
    "\n",
    "`ticdat` allows for a data scientist to define data integrity checks for 4 different categories of problems (in addition to checking for the correct table and field names).\n",
    " 1. Duplicate rows (i.e. duplicate primary key entries in the same table).\n",
    " 1. Data type failures. This checks each column for correct data type, legal ranges for numeric data, acceptable flagging strings, nulls present only for columns that allow null, etc.\n",
    " 1. Foreign key failures, which check that each record of a child table can cross-reference into the appropriate parent table.\n",
    " 1. Data predicate failures. This checks each row for conditions more complex than the data type failure checks. For example, a maximum column can not be allowed to be smaller than the minimum column.\n",
    " \n",
    "For a data scientist building optimization engines, `ticdat` provides bulk-query routines that are part of the `TicDatFactory` and `PanDatFactory` classes. The engine builder can customize those routines to look the data integrity problems that are specific to the problem at hand. Another programmer (i.e. a software engineer embedded the optimization engine into a live system) can then call these subroutines to pre-validate the input data prior to running `solve`. \n",
    "\n",
    "We briefly tour these routines below. Please consult the docstrings for more information regarding their utility.\n",
    "\n",
    "We will first discuss an optimization engine built with `TicDatFactory`. If you wise to organize your code around `pandas.DataFrame` objects, then the `PanDatFactory` examples further down will be more interesting to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrity checking with TicDatFactory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticdat\n",
    "from diet import input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we quickly check that the csv files in `diet_sample_data` represent clean data. The `ticdat` bulk query routines all return \"falsey\" results on clean data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "td: {categories: 4, foods: 9, nutrition_quantities: 36}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = input_schema.csv.create_tic_dat(\"diet_sample_data\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any (_ for _ in [input_schema.csv.find_duplicates(\"diet_sample_data\"),\n",
    "                 input_schema.find_data_type_failures(dat), \n",
    "                 input_schema.find_foreign_key_failures(dat), \n",
    "                 input_schema.find_data_row_failures(dat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we examine the `diet_dirty_sample_data` data set, which has been deliberately seeded with dirty data.\n",
    "\n",
    "We first check for duplicate rows. Note that since the dict-of-dict format that `TicDat` uses will remove any row duplications when representing a data set in memory, we must check for duplications on the csv files directly. Similar duplication checking routines are provided for all the `TicDatFactory` readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nutrition_quantities': {('milk', 'fat'): 2}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema.csv.find_duplicates(\"diet_dirty_sample_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ticdat` is telling us that there are two different records in the Nutrition Quantities table defining the amount of fat in milk. This can be easily confirmed by manually inspecting the \"nutrition_quantities.csv\" file in the \"diet_dirty_sample_data\" directory. In a real-world data set, manual inspection would be impossible and such a duplication would be easily overlooked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TableField(table='nutrition_quantities', field='Quantity'): ValuesPks(bad_values=('',), pks=(('chicken', 'fat'), ('macaroni', 'calories')))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = input_schema.csv.create_tic_dat(\"diet_dirty_sample_data\")\n",
    "input_schema.find_data_type_failures(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('nutrition_quantities', 'Quantity'): (('chicken', 'fat'),\n",
       "  ('macaroni', 'calories'))}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{tuple(k): v.pks for k, v in input_schema.find_data_type_failures(dat).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ticdat` is telling us that there are two rows which have bad values in the Quantity field of the Nutrition Quantities table. In both cases, the problem is an empty data cell where a number is expected. The rows with this problem are those which specify the quantity for `('macaroni', 'calories')` and `('chicken', 'fat')`. As before, these two errant rows can easily be double checked by manually examining \"nutrition_quantities.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('nutrition_quantities', 'foods', ('Food', 'Name')): (('pizza',),\n",
       "  (('pizza', 'calories'),\n",
       "   ('pizza', 'sodium'),\n",
       "   ('pizza', 'protein'),\n",
       "   ('pizza', 'fat')))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema.find_foreign_key_failures(dat, verbosity=\"Low\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `ticdat` is telling us that there are 4 records in the Nutrition Quantities table that fail to cross reference with the Foods table. In all 4 cases, it is specifically the \"pizza\" string in the Food field that fails to find a match from the Name field of the Foods table. If you manually examine \"foods.csv\", you can see this problem arose because of the Foods table was altered to have a \"pizza pie\" entry instead of a \"pizza\" entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TablePredicateName(table='categories', predicate_name='Min Max Check'): ('fat',)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema.find_data_row_failures(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `ticdat` is telling us that the \"Min Max Check\" (i.e. the check that `row[\"Max Nutrition\"] >= row[\"Min Nutrition\"]`) failed for the \"fat\" record of the Categories table. This is easily verified by manual inspection of \"categories.csv\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrity checking with PanDatFactory \n",
    "\n",
    "`PanDatFactory` is a sibling to `TicDatFactory`, geared for developers who prefer input tables organized into `pandas.DataFrame` objects. The syntax for creating a `PanDatFactory` object is nearly identical to `TicDatFactory`. Refer to [`netflow_pd.py`](https://github.com/ticdat/ticdat/blob/develop/examples/gurobipy/netflow/netflow_pd.py) for an example.\n",
    "\n",
    "For expediency, I will close create a `PanDatFactory` clone of the `input_schema` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema_pd = input_schema.clone(clone_factory=ticdat.PanDatFactory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data ingestion is done similarly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pd: {categories: 4, foods: 9, nutrition_quantities: 37}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_pd = input_schema_pd.csv.create_pan_dat(\"diet_dirty_sample_data\")\n",
    "dat_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now present the same integrity check results. Because a `DataFrame` can actually store duplicate rows, the duplicate row check is done with the data object itself (as opposed to the directory of csv files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nutrition_quantities':     Food Category  Quantity\n",
       " 36  milk      fat       1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema_pd.find_duplicates(dat_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other checks are performed the same for `PanDatFactory` as you did for `TicDatFactory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TableField(table='nutrition_quantities', field='Quantity'):         Food  Category  Quantity\n",
       " 22   chicken       fat       NaN\n",
       " 30  macaroni  calories       NaN}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema_pd.find_data_type_failures(dat_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('nutrition_quantities',\n",
       "  'foods',\n",
       "  ('Food', 'Name')):      Food  Category  Quantity\n",
       " 12  pizza    sodium     820.0\n",
       " 13  pizza   protein      15.0\n",
       " 14  pizza  calories     320.0\n",
       " 25  pizza       fat      12.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema_pd.find_foreign_key_failures(dat_pd, verbosity=\"Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TablePredicateName(table='categories', predicate_name='Min Max Check'):   Name  Min Nutrition  Max Nutrition\n",
       " 2  fat             70           65.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema_pd.find_data_row_failures(dat_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `PanDatFactory`, the results are all dictionaries, with `pandas.DataFrame` objects as values. I'll deep dive into each result to demonstrate this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>milk</td>\n",
       "      <td>fat</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Food Category  Quantity\n",
       "36  milk      fat       1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema_pd.find_duplicates(dat_pd)['nutrition_quantities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Category</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pizza</td>\n",
       "      <td>sodium</td>\n",
       "      <td>820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pizza</td>\n",
       "      <td>protein</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pizza</td>\n",
       "      <td>calories</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pizza</td>\n",
       "      <td>fat</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Food  Category  Quantity\n",
       "12  pizza    sodium     820.0\n",
       "13  pizza   protein      15.0\n",
       "14  pizza  calories     320.0\n",
       "25  pizza       fat      12.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk_fails = input_schema_pd.find_foreign_key_failures(dat_pd, verbosity=\"Low\")\n",
    "fk_fails['nutrition_quantities', 'foods', ('Food', 'Name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema_pd.find_data_row_failures(dat_pd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
