{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ticdat to build modular engines\n",
    "\n",
    "The goal of the `ticdat` package is to facilitate solve engines that are modular and robust. For example, the multicommodity `netflow.py` engine can read and write from a variety of file types when run from the the command line. It can also be run from a Python script that contains embedded static data, or from a script that reads and writes from a system-of-record data source such as an ERP system. \n",
    "\n",
    "With regards to the latter, we should note that Python is one of the most popular \"glue\" [languages](https://en.wikipedia.org/wiki/Scripting_language#Glue_languages). The market has recognized that Python scripts are easy to write, manage data with intuitive programming syntax, and can be connected to nearly any data source.\n",
    "\n",
    "The `ticdat` package can easily be used in any Python glue script. One way to do this is to exploit `ticdat`'s ability to recognize data tables as list-of-lists. The inner lists contain data values in the field order defined by by the `PanDatFactory` (i.e. `netflow.input_schema`).\n",
    "\n",
    "For example, suppose the `netflow` engine needs to connect to an Oracle database for a daily automated solve. The integration engineer can use the `cx_Oracle` [package](https://oracle.github.io/python-cx_Oracle/) (or something equivalent) to turn system data into a list-of-lists for each input table. These data structures can then be used to create a `PanDat` object that can be passed as input data to `netflow.solve`. The solution `PanDat` object returned by `netflow.solve` can then be converted back into a list-of-lists representation of each solution report table. (The list-of-lists strategy is just one approach. It might make sense to convert system-of-record data into `pandas.DataFrame` objects, and then use these `DataFrame`s to build the `PanDat` object.)\n",
    "\n",
    "We demonstrate this approach without explicit references to `cx_Oracle`. By demonstrating that `ticdat` is compatible with list-of-list/`DataFrame` table representations we thus show that `ticdat` is compatible with any data source that can be connected to Python, and also with human readable static data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodities = [['Pencils', 0.5], ['Pens', 0.2125]]\n",
    "\n",
    "# a one column table can just be a simple list \n",
    "nodes = ['Boston', 'Denver', 'Detroit', 'New York',  'Seattle']\n",
    "\n",
    "cost = [['Pencils', 'Denver', 'Boston', 10.0],\n",
    "        ['Pencils', 'Denver', 'New York', 10.0],\n",
    "        ['Pencils', 'Denver', 'Seattle', 7.5],\n",
    "        ['Pencils', 'Detroit', 'Boston', 2.5],\n",
    "        ['Pencils', 'Detroit', 'New York', 5.0],\n",
    "        ['Pencils', 'Detroit', 'Seattle', 15.0],\n",
    "        ['Pens', 'Denver', 'Boston', 15.0],\n",
    "        ['Pens', 'Denver', 'New York', 17.5],\n",
    "        ['Pens', 'Denver', 'Seattle', 7.5],\n",
    "        ['Pens', 'Detroit', 'Boston', 5.0],\n",
    "        ['Pens', 'Detroit', 'New York', 5.0],\n",
    "        ['Pens', 'Detroit', 'Seattle', 20.0]]\n",
    "\n",
    "inflow = [['Pencils', 'Boston', -200],\n",
    "          ['Pencils', 'Denver', 240],\n",
    "          ['Pencils', 'Detroit', 200],\n",
    "          ['Pencils', 'New York', -200],\n",
    "          ['Pencils', 'Seattle', -40],\n",
    "          ['Pens', 'Boston', -160],\n",
    "          ['Pens', 'Denver', 160],\n",
    "          ['Pens', 'Detroit', 240],\n",
    "          ['Pens', 'New York', -120],\n",
    "          ['Pens', 'Seattle', -120]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An integration engineer might prefer to copy system-of-records data into `pandas.DataFrame` objects. Note that `pandas` is itself [capable](https://stackoverflow.com/questions/35781580/cx-oracle-import-data-from-oracle-to-pandas-dataframe) of reading directly from various SQL databases, although it usually needs a supporting package like `cx_Oracle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>Source</th>\n",
       "      <th>Capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Denver</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>Denver</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Denver</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Destination   Source  Capacity\n",
       "0      Boston   Denver       120\n",
       "1    New York   Denver       120\n",
       "2     Seattle   Denver       120\n",
       "3      Boston  Detroit       100\n",
       "4    New York  Detroit        80\n",
       "5     Seattle  Detroit       120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "arcs = DataFrame({\"Source\": [\"Denver\", \"Denver\", \"Denver\", \"Detroit\", \"Detroit\", \"Detroit\",], \n",
    "                 \"Destination\": [\"Boston\", \"New York\", \"Seattle\", \"Boston\", \"New York\", \n",
    "                                 \"Seattle\"], \n",
    "                 \"Capacity\": [120, 120, 120, 100, 80, 120]})\n",
    "#  PanDatFactory doesn't require the fields to be in order so long as the field names are supplied\n",
    "arcs = arcs[[\"Destination\", \"Source\", \"Capacity\"]]\n",
    "arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a `PanDat` input data object from the list-of-lists/`DataFrame` representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netflow import input_schema, solve, solution_schema\n",
    "dat = input_schema.PanDat(commodities=commodities, nodes=nodes, cost=cost, arcs=arcs, \n",
    "                          inflow=inflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a `PanDat` solution data object by calling `solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi 7.5.0: optimal solution; objective 5627.5\n",
      "3 simplex iterations\n"
     ]
    }
   ],
   "source": [
    "sln = solve(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a list-of-lists representation of the solution data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sln_lists = {t: list(map(list, getattr(sln, t).itertuples(index=False))) \n",
    "             for t in solution_schema.all_tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate that `sln_lists` is a dictionary mapping table name to list-of-lists of solution report data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**\n",
      "Solution Table parameters\n",
      "**\n",
      "[['Total Cost', 5627.5]]\n",
      "\n",
      "\n",
      "**\n",
      "Solution Table flow\n",
      "**\n",
      "[['Pencils', 'Denver', 'Boston', 51.0],\n",
      " ['Pencils', 'Denver', 'New York', 149.0],\n",
      " ['Pencils', 'Denver', 'Seattle', 40.0],\n",
      " ['Pencils', 'Detroit', 'Boston', 149.0],\n",
      " ['Pencils', 'Detroit', 'New York', 51.0],\n",
      " ['Pens', 'Denver', 'Boston', 40.0],\n",
      " ['Pens', 'Denver', 'Seattle', 120.0],\n",
      " ['Pens', 'Detroit', 'Boston', 120.0],\n",
      " ['Pens', 'Detroit', 'New York', 120.0]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for sln_table_name, sln_table_data in sln_lists.items():\n",
    "    print(\"\\n\\n**\\nSolution Table %s\\n**\"%sln_table_name)\n",
    "    pprint.pprint(sln_table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the solution data object itself contains `DataFrames`, if that representation is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Boston</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>Denver</td>\n",
       "      <td>New York</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Boston</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>New York</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pens</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Boston</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pens</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pens</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Boston</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pens</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>New York</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Commodity   Source Destination  Quantity\n",
       "0   Pencils   Denver      Boston      51.0\n",
       "1   Pencils   Denver    New York     149.0\n",
       "2   Pencils   Denver     Seattle      40.0\n",
       "3   Pencils  Detroit      Boston     149.0\n",
       "4   Pencils  Detroit    New York      51.0\n",
       "5      Pens   Denver      Boston      40.0\n",
       "6      Pens   Denver     Seattle     120.0\n",
       "7      Pens  Detroit      Boston     120.0\n",
       "8      Pens  Detroit    New York     120.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sln.flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ticdat to build robust engines\n",
    "\n",
    "The preceding section demonstrated how we can use `ticdat` to build modular engines. We now demonstrate how we can use `ticdat` to build engines that check `solve` pre-conditions, and are thus robust with respect to data integrity problems.\n",
    "\n",
    "First, lets violate our (somewhat artificial) rule that the commodity volume must be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pens</td>\n",
       "      <td>0.2125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Volume\n",
       "0  Pencils  0.0000\n",
       "1     Pens  0.2125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.commodities.loc[dat.commodities[\"Name\"] == \"Pencils\", \"Volume\"] = 0\n",
    "dat.commodities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `input_schema` can not only flag this problem, but give us a useful data structure to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TableField(table='commodities', field='Volume'):       Name  Volume\n",
       " 0  Pencils     0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_failures = input_schema.find_data_type_failures(dat)\n",
    "data_type_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pencils</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Volume\n",
       "0  Pencils     0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_failures['commodities', 'Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets add a Cost record for a non-existent commodity and see how `input_schema` flags this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('cost',\n",
       "  'commodities',\n",
       "  ('Commodity', 'Name')):    Commodity   Source Destination  Cost\n",
       " 12   Crayons  Detroit     Seattle  10.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.cost = dat.cost.append({'Commodity':'Crayons', 'Source': 'Detroit', \n",
    "                            'Destination': 'Seattle', 'Cost': 10}, \n",
    "                           ignore_index=True)\n",
    "fk_failures = input_schema.find_foreign_key_failures(dat, verbosity=\"Low\")\n",
    "fk_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crayons</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Commodity   Source Destination  Cost\n",
       "12   Crayons  Detroit     Seattle  10.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk_failures['cost', 'commodities', ('Commodity', 'Name')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life, data integrity failures can typically be grouped into a small number of categories. However, the number of failures in each category might be quite large. `ticdat` creates data structures for each of these categories that can themselves be examined programmatically. As a result, an analyst can leverage the power of Python and `pandas` to detect patterns in the data integrity problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
